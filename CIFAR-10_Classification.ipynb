{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21f2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3644fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a53238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset)) #50,000 images all 32x32 and 3 RGB\n",
    "print(len(testset)) #10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89be2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "def get_image(index):\n",
    "    image, label = trainloader.dataset.__getitem__(index)\n",
    "    plt.imshow(vutils.make_grid(image, normalize=True).numpy().transpose((1,2,0)))\n",
    "    plt.xlabel(classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a28be399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEHCAYAAABoVTBwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAclUlEQVR4nO2deYxc13Xmv1NrV+8km6Saa5MUvciMTcvUAsuJt8RmHGNkI7BhZWIIiRFmMBESIwkwggOMneQfz2BsQ4MADuixEDkjb4mtWAg0iQx6ZgTZsmJJlihRJCVKbonNbnWz2ftey8kfVQIo+X6vm13dVS3e7wc0qvqeuu+dd+t99arueedcc3cIIa5+Us12QAjRGCR2ISJBYhciEiR2ISJBYhciEiR2ISIhU09nMzsK4C4AaQD/y92/uMzrFedbAwxGbU5MqSwf+nw+4TPfuW1hvsy7lZmPSafAxj890nzokU3zsaqU+bEVSfh7taPhHj4LbLVxdjNLA3gOwG8AGADwMwC3ufuzCX02/rvZSBLOnLSnqS1X4bZithJsb+kt0T77D7RTW6rSRm1nn5qktsXJ8LEZirRPxRI+PKgFAMLHXCUsQEv4Upt27kdXjo99b2eB2qZnFqhtcDE8JsUUPz+sQj4gKlzs9XyNvxHAOXd/0d2XAHwbwK11bE8IsY7UI/adAM5f9v9ArU0IsQGp5zd76KvCL323MLNjAI7VsR8hxBpQj9gHAOy+7P9dAAZf/yJ3Pw7gOKDf7EI0k3q+xv8MwEEz22dmOQCfAnD/2rglhFhrVn1ld/eSmd0B4F9RDb3d7e6n1syzKEj4omN8hrmMLLdlwjPJvYf4TPFbbuJudOT57PPFUT5Tf2Ei7GM6Pc53ljBTj0qO24xHGhiphChUPuFt2ZzjkkknvJ+zZT7DTybWgUpCnI/Cfagrzu7uDwB4oJ5tCCEag+6gEyISJHYhIkFiFyISJHYhIkFiFyIS6pqNXw1mVx5OuGqLYq4msgIkhuWMRcM28TG0Hr69dG6C2rb38XDYhTPhMJojIUzGUvaAxOy7RNh9XAn3d2Wz3I98nu9qqrhIbTNlPsYVetxJx8z85yE+XdmFiASJXYhIkNiFiASJXYhIkNiFiISGz8aLy0n4rE1KgkjzGe3WnvB08djSEu3TP8qTXd7R10pt193EbRfOXgq2D7+YNFvMp7pXH48Jj2MlYTa+0M2Py3k+ESYu8dn4haTKWcRHSyhNxktx8R3pyi5EJEjsQkSCxC5EJEjsQkSCxC5EJEjsQkRCpKG3hJU2kpZWuuKtAZ4QNDLnw5/UL9fFP6PzW8LJKZUUr1tntoXaZks8zNe5m4fR3vqr4TDa5CgPDS1M8NBbKqk+XQIVUlCucyevn7fjLduprTw/RW2LszPckfmEc47WoOPjyxfX4ueNruxCRILELkQkSOxCRILELkQkSOxCRILELkQk1BV6M7N+ANOoFr4qufuR5fpshHpyqyiDV+23iqJxST2Stmc8UoaWa3iIqtwZ7phLWLbouh191Nbe+hL3ozBGbde/N3wdyVZ4yOvZR3hm3sw4D71ZQs24FpK1Z7t5/byBLF+iqpxOqF23dzO1ZcqzfJsz4Wy5pCWqWLguKbluLeLs73f30TXYjhBiHdHXeCEioV6xO4AHzexxMzu2Fg4JIdaHer/G3+Lug2a2DcAPzeyMuz90+QtqHwL6IBCiydR1ZXf3wdrjCID7ANwYeM1xdz+yksk7IcT6sWqxm1mbmXW8+hzAhwA8s1aOCSHWlnq+xm8HcF9tOacMgG+6+7+siVfrTlL4bxWhweS0N97NE5ZdSqg1mOricbm5bDhTaldHN+3zgQNvoba9Xe3UNr3ED25263yw/e17eEbZ6K38uIZeWaC2sXBty2q/xclg+8BcuB0ALk7wbLNF45LJJxTn7Ork/SaeCof6UjwCiAo9sXiW4qrF7u4vAnjHavsLIRqLQm9CRILELkQkSOxCRILELkQkSOxCRMJVXHAyaZ0snvEES8obYiGZpNgbH+JUJcGWEELZ0bef2npuujbYfuOeHbTPoZ7d1La15QC1lXM3UNuih+NhMyVelNH3JcQpsy3UNFfiWYCX5kbC7bMXaZ9F59fAmYSakv/0k2ep7WzCGnft093B9qmT07SPl8j2EtYI1JVdiEiQ2IWIBIldiEiQ2IWIBIldiEi4emfjjX+OedJhV3jCBVLhmXpLJxSMq3BbOWHmNMMnmNFS4JGG0kJ4uvipk4/TPqmzj1JbZw93ZM/Bg9y2PVxrrpBOGN8pntHi4H5kC3ym/s2dYT86eq6nfSYnefJPactOanv44bup7cejD1Hb5t5wclBhPiEC0U8Seea1/JMQ0SOxCxEJErsQkSCxCxEJErsQkSCxCxEJV2/ojSatAO18lR70XctDK+Pj4aJgQ4O8npk59yPfzod/8x4eQpmfe5raJl4Ob3P7Np78M5TjSTdTCaHIicF+ajtPwlft7eHEFABoSXM/vFygtlSaj/EWC4feegtvpn1GBnnobWTmFWrra++jts2pk9Q2lw4nvLQe4jXtSovh97N4ni+hpSu7EJEgsQsRCRK7EJEgsQsRCRK7EJEgsQsRCcuG3szsbgAfBTDi7odqbZsBfAdAH4B+AJ9094TFal6zRdKetOxSuI8luO9pXkvurTduo7Z3H+W12s4Phv04f45nZKUrPCzUvZ37uGVnwjJD7bxffgvJNuvkobeW9BzfXkItvGy2SG2lVDgENJ/nmVzlAt9XwXkYqmUpvNQUAJQqw8H2ae+mfXoO8kzFTbkp3m96F7U9cpbHe38++mKwvdTJ/ei5bmuw/eLF8PECK7uy/x2Ao69ruxPACXc/COBE7X8hxAZmWbHX1lsfe13zrQDuqT2/B8DH1tYtIcRas9rf7NvdfQgAao/8e7EQYkOw7rfLmtkxAMfWez9CiGRWe2UfNrNeAKg90hue3f24ux9x9yOr3JcQYg1YrdjvB3B77fntAH6wNu4IIdaLlYTevgXgfQB6zGwAwOcBfBHAd83sMwBeBvCJle+Sfb5ceegtadmlXAs/tAO/0kVt6a08K6tcnab4JXbu5NsrZLiP7QV+zJu6eDgvlebHVq6Ew3L5Fl6k0sGzvDJ5HjLKZ/m1Ikey/Xpa+L46jGfYdWb5OObTPFNxaKAv2D6V5sfV0cNDm0Xn58fwCPc/leG2rk3hjL7xJR4S7djcHTYknG/Lit3dbyOmDy7XVwixcdAddEJEgsQuRCRI7EJEgsQuRCRI7EJEwgYqOJn0uRMOUXlCRlYmKdSUkLk0N7dIbUb217lplvbJJYTJMglhEs9xP1paeDZUysIhu2zC4nGVEh/77vw11LatjffrKIXDlL1ZHm7s8V5qy6a5/xdmeabi+Ln9wfbdh/i6cjOz/5/ayt7J/Rjh5+PQJM8QnE+Fx8QyfHynFyeC7eWEAqe6sgsRCRK7EJEgsQsRCRK7EJEgsQsRCRK7EJHwhgi9mYWzkDwhzJDmS4NhChPUVpjjIbvDm68Nth/Yup32aa2EC0ACwGxmkNrG/AVqSxV5+KqjEM7Ayxkf39aETLSehMy2bTk+/m2FcIHL9lQ37VPIvI3apqZ5WO7sz3nBSaTD4c3O3gu0y+g8zzYrZA9R20vD4cKRAHBhNLyeGwCgg+yLZMMBQHE+fMwOnrGnK7sQkSCxCxEJErsQkSCxCxEJErsQkfAGmY2/8q3t3NtNbZ3chC2dfCa2MtITbP/pv/LZ4K5ceBkkADjyYT7beuBtb6K2hSk+G9/dEi7h354J+w4ALRkyHQygNWE2vpDiyR056wsbMnton1k7yG2ZA9TWsXWA2rbufDC8vew52sdLfOb/lQm+jNbTz/HoSqnMx6q1El4Sy2Z4tKM0R7ZX5ueGruxCRILELkQkSOxCRILELkQkSOxCRILELkQkrGT5p7sBfBTAiLsfqrV9AcAfALhYe9nn3P2B+lxJ+twJ39yf4jkr2NHDl2R6204enjhyhNc6O/H34bpl93z7Zdpn624+xDvew5Mqbu69idp8M0+uacXWYHtqIRzeAYB8mm9vMc/Ho8xLrsGXwv28uIn2aWnhteSW2riPHbvOUNt82/lg++wCD3u2FrZQ2yv9w9Q2OsdrG1qOn3OV+XAYbYmXNkQqzU7++kJvfwfgaKD9K+5+uPZXp9CFEOvNsmJ394cAjDXAFyHEOlLPb/Y7zOykmd1tZvy7mRBiQ7BasX8VwAEAhwEMAfgSe6GZHTOzx8zssVXuSwixBqxK7O4+7O5ld68A+BqAGxNee9zdj7j7kdU6KYSon1WJ3cwuzxT4OIBn1sYdIcR6sZLQ27cAvA9Aj5kNAPg8gPeZ2WFU5/n7Afxh/a7wDB9YOJxQ4VEG5BIy5Q7tDGeGAcC1XTx80vr+cFhr5GmeKde9h2d5vfuGX6U2W9hMbZnUPmqbnQvXkxu/EF6OCQA2tfLBKnXz0FtbK/dxFuFt5rOtvM+lcWr7yal/obbWXn5slU3h82rcea22nnk+HheH+bJR810L1NaW4XHihbGwrTzH/egohK/TReM6Wlbs7n5boPnry/UTQmwsdAedEJEgsQsRCRK7EJEgsQsRCRK7EJHQhIKTLJzAQwZOwiSeEHo738/DOGODPLsKe/ZS03UHw8s//cWdvFDi6EKW2qYu8mKUS8M8NLQvoZjm7KXwOI6N8cGanubpa93TvBhlscALbY7bxWD7udHnaJ8Tj/2I2jJZfn58dM+bqW12NrzskrXy8a3Mc1lMTPKx8jzv15oQeiuXwtukiW0AFkuLYR8SRKEruxCRILELEQkSuxCRILELEQkSuxCRILELEQkbaK03HgrxSthmCR9Vzz0bDrkAwFf++gVqe/BNPCsrUw4XlpyafIL2mVzkoZoPHf11ajuwgxdEHB/gdUCOfvg3gu2FLj5YX/vf36S2kSFeYDG9LRz+AQBrC4/VmYmztM85n6S237r+Fu5HC+9XmgufB10ZXlxpssiLc54bnqC2qUt8PJacnwc5UoxySzf3Y/piOC5XTPH96MouRCRI7EJEgsQuRCRI7EJEgsQuRCQ0YTae3aifkNXCeiR0KS7yQzt1iq+r8+ypEWpLk4hBBTzZJYUctV0Y5hGDpYS1f1qz/MB/57kng+2//bu30j7b9/HP/H889w/UVuSHhnd0hxNosoXwUkcAkCFLRgHANVt4lCRd4LPgeQ9HNXILPMHniQFeZ+70GLc5eOZKOsfHuKUQPq9yrXx7rYvh7c2neXKVruxCRILELkQkSOxCRILELkQkSOxCRILELkQkrGT5p90AvgHgGlSzVY67+11mthnAdwD0oboE1CfdnRd+W5YrD73BecgrCUvx5ZrM+JI7FZZ5Yzz5oFzmtdNeHDhDbekOHobaup0vKfWl+8JJLecX+b7+y3/+D9Q2vY2u2YkfFS9Q27aJ7mD7hVG+VNNSMVy3DgCKCSGvpX38PFhyEr66xN+zH7/4IrWNd/B+nRkeHqwYl5qXwstGTU7yGn9pmgVWXw26EoA/c/e3ArgZwB+Z2XUA7gRwwt0PAjhR+18IsUFZVuzuPuTuT9SeTwM4DWAngFsB3FN72T0APrZOPgoh1oAr+s1uZn0A3gngUQDb3X0IqH4gAOBLowohms6Kb5c1s3YA3wPwWXefSvpt+7p+xwAcW517Qoi1YkVXdjPLoir0e939+7XmYTPrrdl7AQRvKnf34+5+xN2PrIXDQojVsazYrXoJ/zqA0+7+5ctM9wO4vfb8dgA/WHv3hBBrxUq+xt8C4NMAnjazJ2ttnwPwRQDfNbPPAHgZwCfq8iTpVwGNJqzsp8Qvba7C+3nSkBipk2c8vIYK396uPl4H7eB79lHbaEK2WWo+HLLrnwnXhAOA+eknqe19e6+jttKlw9TWWQpnmy1WHqd9bugLh6AA4Jqt/KCLSzyUurgU7tc/wPucH+d+IMPfz/lZvs2lIu9XWghnAqYS6jJu2RIOKSbVZVxW7O7+MLiqPrhcfyHExkB30AkRCRK7EJEgsQsRCRK7EJEgsQsRCU0oOEnCVKtIegN48cJkkkJ2vGAf8zE5asi311rg2VrbuvnyT6MVnsG27U37g+17unmm3Gixn9r2776J7+vSLmobbgkXgdy69wbaZ3N5itoKeZ4R15Hi2WFnhmeC7f/nFM/YGxnjBSzLSzwstzDH3+uK8/CsOyk42cXPj0yW2Iz7riu7EJEgsQsRCRK7EJEgsQsRCRK7EJEgsQsRCU0Iva0lq4rX1dGPbG2Vm3vp+VFqG5vla73t+CgvRrnrzeFMurbMDtrn5XFeJ/TwgS3UVpnhYahfkAKRm1q6aJ/2uXZqwxy/Lr00P0Btz74QDtm9PM4LX87M85BuuchDaKkU99EqvF+ZnEClOV7ccm4snPVW4V10ZRciFiR2ISJBYhciEiR2ISJBYhciEt7gs/FvbJaW+DT+9ARPaMhn+Gx8CeEEj0sL3bTPbNt2apsZ49eDtixP1hmb7g+2W6GF9tnWeQ21XRgZpLYXRiapbSnXGTbkeX03L/Kxz+T5Ek8ZVqMQQMp4kgzLrSkv8Bn8+Ymwzcv1Lf8khLgKkNiFiASJXYhIkNiFiASJXYhIkNiFiIRlQ29mthvANwBcA6AC4Li732VmXwDwBwBezTT4nLs/sF6OXp3wcIx7QlJFiWc7LEwG19fEbGUv7TNT2Ultg8O8wl6RLK0EAHOT08H2rhYeujp5/mlq+8UrP6a2PQd5fb3xuXB9unImnEgCAKWERKlclofD0jwSiYTdodAVDqUuTPFQ3tJ0+H3xhIqIK4mzlwD8mbs/YWYdAB43sx/WbF9x9/+xgm0IIZrMStZ6GwIwVHs+bWanAfBLgRBiQ3JFv9nNrA/AOwE8Wmu6w8xOmtndZsaXJBVCNJ0Vi93M2gF8D8Bn3X0KwFcBHABwGNUr/5dIv2Nm9piZPVa/u0KI1bIisZtZFlWh3+vu3wcAdx9297JXK9x/DcCNob7uftzdj7j7kbVyWghx5SwrdjMzAF8HcNrdv3xZe+9lL/s4gGfW3j0hxFqxktn4WwB8GsDTZvZkre1zAG4zs8OoFnTrB/CH6+DfVY2leYinNaFWW3f2ILXt6A5nsHVXbqZ9tmd5fboJXmYOEzM8DPWW3fuC7eMzvF7c2fHnqG0w009twy+Fw40AUCT+ZxPGN5Ob47bWhNBbO792ZvI8TNnZ2hZsz7fyEOtoKXxgluLn1Epm4x9GeDkzxdSFeAOhO+iEiASJXYhIkNiFiASJXYhIkNiFiAQVnGwiuVyW2m679WPUdvC9B6htYlt46aLWS7tpn3wrX+JpohzOGgOAdJ6HhvZsCqdP9L/CM9uG539BbTNZvhzW2OgEtbXlwktKtbfypaayxlPUEqKlqCzxa2cxxzsWM+H3rK2DFxZt7e0OtvdneWFOXdmFiASJXYhIkNiFiASJXYhIkNiFiASJXYhIUOitiaRSvDhg2vl6YxMT/dT2Si6cDdUzzkNNpycvUdueXTzMl+OJY/jxzx8Jtj8//DztM1sKF6kEAK/wNeJaW7kj6QrJUivzsGEuQRYzl3iRUMvxfln+VmORRGD3t/fRPvn5cGGoQRujfXRlFyISJHYhIkFiFyISJHYhIkFiFyISJHYhIkGhtyYyv8jDP9+5735qe9dmnsGWawuvpZYv80V8Olv3U9tiQqHE/otnqO3xgR8F28cqCcUh0zy8tm37tdTWmef9Rs+HM+lSRT72LSmebTbDQnkA2tt5CDCb57G3npbOYLtdDBeiBIAnHwgX55yf5BVCdWUXIhIkdiEiQWIXIhIkdiEiQWIXIhKWnY03sxYADwHI117/j+7+eTPbDOA7APpQXf7pk+4+vn6uXn2488/aqQWecOHZhJnkrvCsb3kpXOcMANIFPuM+OssTKx459RC1Dc31B9u9wGux9fbwpJt3v/O91PbCc3yB4LlLo8H2be0F2ief5z5OJ4x9qThBbc5XlEKqEJ79P/8Mr8k3enYo7MMif59XcmVfBPABd38HqsszHzWzmwHcCeCEux8EcKL2vxBig7Ks2L3KTO3fbO3PAdwK4J5a+z0APrYeDgoh1oaVrs+erq3gOgLgh+7+KIDt7j4EALXHbevmpRCiblYkdncvu/thALsA3Ghmh1a6AzM7ZmaPmRn/YSWEWHeuaDbe3ScA/D8ARwEMm1kvANQeg/dBuvtxdz/i7kfqc1UIUQ/Lit3MtppZd+15AcCvAzgD4H4At9dedjuAH6yTj0KINWAliTC9AO4xszSqHw7fdfd/NrNHAHzXzD4D4GUAn1hHP69OjId4vMxtizN82aiFmXBSyMTYTLAdAMqLPMQzW+T9hodeora0hcN57WQ5JgA41PtWaisO8uWfJl7mEd9DO94UbK+M8z5l52HPKfDlsOYWed1AT1WobWEyvM25CZ50UymGfXTn582yYnf3kwDeGWi/BOCDy/UXQmwMdAedEJEgsQsRCRK7EJEgsQsRCRK7EJFgSVP1a74zs4sAXo3X9AAIpyQ1FvnxWuTHa3mj+bHX3beGDA0V+2t2bPbYRrirTn7Ij1j80Nd4ISJBYhciEpop9uNN3PflyI/XIj9ey1XjR9N+swshGou+xgsRCU0Ru5kdNbOzZnbOzJpWu87M+s3saTN7spHFNczsbjMbMbNnLmvbbGY/NLPna4+bmuTHF8zsQm1MnjSzjzTAj91m9n/N7LSZnTKzP6m1N3RMEvxo6JiYWYuZ/ZuZPVXz4y9r7fWNh7s39A9AGsALAPYDyAF4CsB1jfaj5ks/gJ4m7PfXAFwP4JnL2v47gDtrz+8E8N+a5McXAPx5g8ejF8D1tecdAJ4DcF2jxyTBj4aOCQAD0F57ngXwKICb6x2PZlzZbwRwzt1fdPclAN9GtXhlNLj7QwBeX6O54QU8iR8Nx92H3P2J2vNpAKcB7ESDxyTBj4biVda8yGszxL4TwPnL/h9AEwa0hgN40MweN7NjTfLhVTZSAc87zOxk7Wv+uv+cuBwz60O1fkJTi5q+zg+gwWOyHkVemyH20CoGzQoJ3OLu1wP4TQB/ZGa/1iQ/NhJfBXAA1TUChgB8qVE7NrN2AN8D8Fl3n2rUflfgR8PHxOso8spohtgHAFy+wPguAINN8APuPlh7HAFwH6o/MZrFigp4rjfuPlw70SoAvoYGjYmZZVEV2L3u/v1ac8PHJORHs8aktu8JXGGRV0YzxP4zAAfNbJ+Z5QB8CtXilQ3FzNrMrOPV5wA+BOCZ5F7ryoYo4PnqyVTj42jAmJiZAfg6gNPu/uXLTA0dE+ZHo8dk3Yq8NmqG8XWzjR9BdabzBQB/0SQf9qMaCXgKwKlG+gHgW6h+HSyi+k3nMwC2oLqM1vO1x81N8uPvATwN4GTt5OptgB/vQfWn3EkAT9b+PtLoMUnwo6FjAuDtAH5e298zAP5rrb2u8dAddEJEgu6gEyISJHYhIkFiFyISJHYhIkFiFyISJPaIMbM/rmV43dtsX8T6o9BbxJjZGQC/6e6/uKwt4+6lJrol1gld2SPFzP4W1RuL7jezSTM7bmYPAviGme01sxO1xI8TZran1ueAmf3UzH5mZn9lZnyJV7HhkNgjxd3/E6o5Ce8H8BUA7wJwq7v/DoC/AfANd387gHsB/M9at7sA3OXuN6BJ+Qxi9ehrfMSYWT+AIwDuQDWN+tWKKKOo3hJarCWGDLl7j5ldQjXNsmRmnQAG3Z0vuC42FLqyi1eZTbDpinAVILGLED9BNRsRAP4jgIdrz38K4Ldrzz/1+k5iYyOxixB/DOD3zOwkgE8D+JNa+2cB/KmZ/Ruq9domm+OeWA36zS5WjJm1Aph3dzezTwG4zd2jqh/4RibTbAfEG4p3AfibWpGHCQC/31x3xJWgK7sQkaDf7EJEgsQuRCRI7EJEgsQuRCRI7EJEgsQuRCT8O5M/IKq6h1f9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_image(104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ee94cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2314, 0.1686, 0.1961,  ..., 0.6196, 0.5961, 0.5804],\n",
       "          [0.0627, 0.0000, 0.0706,  ..., 0.4824, 0.4667, 0.4784],\n",
       "          [0.0980, 0.0627, 0.1922,  ..., 0.4627, 0.4706, 0.4275],\n",
       "          ...,\n",
       "          [0.8157, 0.7882, 0.7765,  ..., 0.6275, 0.2196, 0.2078],\n",
       "          [0.7059, 0.6784, 0.7294,  ..., 0.7216, 0.3804, 0.3255],\n",
       "          [0.6941, 0.6588, 0.7020,  ..., 0.8471, 0.5922, 0.4824]],\n",
       " \n",
       "         [[0.2431, 0.1804, 0.1882,  ..., 0.5176, 0.4902, 0.4863],\n",
       "          [0.0784, 0.0000, 0.0314,  ..., 0.3451, 0.3255, 0.3412],\n",
       "          [0.0941, 0.0275, 0.1059,  ..., 0.3294, 0.3294, 0.2863],\n",
       "          ...,\n",
       "          [0.6667, 0.6000, 0.6314,  ..., 0.5216, 0.1216, 0.1333],\n",
       "          [0.5451, 0.4824, 0.5647,  ..., 0.5804, 0.2431, 0.2078],\n",
       "          [0.5647, 0.5059, 0.5569,  ..., 0.7216, 0.4627, 0.3608]],\n",
       " \n",
       "         [[0.2471, 0.1765, 0.1686,  ..., 0.4235, 0.4000, 0.4039],\n",
       "          [0.0784, 0.0000, 0.0000,  ..., 0.2157, 0.1961, 0.2235],\n",
       "          [0.0824, 0.0000, 0.0314,  ..., 0.1961, 0.1961, 0.1647],\n",
       "          ...,\n",
       "          [0.3765, 0.1333, 0.1020,  ..., 0.2745, 0.0275, 0.0784],\n",
       "          [0.3765, 0.1647, 0.1176,  ..., 0.3686, 0.1333, 0.1333],\n",
       "          [0.4549, 0.3686, 0.3412,  ..., 0.5490, 0.3294, 0.2824]]]),\n",
       " 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b58860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss ###PERHAPS THIS IS A PROBLEM LOOK AT THE INPUT AND WHAT THE STRUCTURE OF INPUTT MUST BE\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53cb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "init_channels = 6\n",
    "kernel_size = 3\n",
    "\n",
    "class ClassificationModel(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, out_channels=init_channels, kernel_size=kernel_size, padding=0), #30x30x6\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(init_channels, out_channels=init_channels*2, kernel_size=kernel_size, padding=0), #28x28x12\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(init_channels*2, out_channels=init_channels*4, kernel_size=kernel_size, padding=0), #26x26x24\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(init_channels*4, out_channels=init_channels, kernel_size=kernel_size, padding=0), #24x24x6\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(24*24*6, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "    )\n",
    "    def forward(self, xb):\n",
    "        return self.cnn(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eaa5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "  \n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "  \n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func):\n",
    "    \n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(),lr)\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ee841c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], train_loss: 1.7635, val_loss: 1.5296, val_acc: 0.4464\n",
      "Epoch [1], train_loss: 1.4297, val_loss: 1.3499, val_acc: 0.5156\n",
      "Epoch [2], train_loss: 1.3048, val_loss: 1.2886, val_acc: 0.5356\n",
      "Epoch [3], train_loss: 1.2177, val_loss: 1.2519, val_acc: 0.5501\n",
      "Epoch [4], train_loss: 1.1534, val_loss: 1.2181, val_acc: 0.5606\n",
      "Epoch [5], train_loss: 1.0824, val_loss: 1.2429, val_acc: 0.5657\n",
      "Epoch [6], train_loss: 1.0067, val_loss: 1.1653, val_acc: 0.5952\n",
      "Epoch [7], train_loss: 0.9397, val_loss: 1.1123, val_acc: 0.6085\n",
      "Epoch [8], train_loss: 0.8759, val_loss: 1.1065, val_acc: 0.6149\n",
      "Epoch [9], train_loss: 0.8126, val_loss: 1.1355, val_acc: 0.6098\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "opt_func = torch.optim.Adam\n",
    "lr = .001\n",
    "model = ClassificationModel()\n",
    "\n",
    "history = fit(num_epochs, lr, model, trainloader, testloader, opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09c8c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.98\n",
      "accuracy = 60.98\n"
     ]
    }
   ],
   "source": [
    "number_correct = 0\n",
    "for images, labels in testloader:\n",
    "    outputs = model(images)\n",
    "    \n",
    "    #print(outputs)\n",
    "    predictions = torch.argmax(outputs, dim=1)\n",
    "    #print(predictions)\n",
    "    #print(labels.data)\n",
    "    number_correct += torch.sum(predictions == labels.data)\n",
    "    #print(number_correct)\n",
    "    \n",
    "accuracy = 100*number_correct/len(testloader.dataset)\n",
    "print(\"accuracy = \" + str(accuracy.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e913b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
